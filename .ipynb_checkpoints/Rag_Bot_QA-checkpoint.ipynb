{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7145227-1b11-4a78-97ab-fe73a1393b52",
   "metadata": {},
   "source": [
    "### Rag Bot for Q/A from a pdf document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00d00e7-5fcb-4102-bed8-813d582cc499",
   "metadata": {},
   "source": [
    "`PypdfLoader` is used to load the file so that it can be analysed by the bot. Here we will use the `Sample_Financial_Statement.pdf` but for the web application which will be built later, we will allow the user to upload the document. An interesting note is that the `PypdfLoader` loads the pdf file as pages and not as a complete document. We can access the specific page of the document by indexing the page within `[]`. For example if we want to access the page 6, we will print it as `print(data[6])`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f50442d-6383-44e5-9303-5bf8dfba25c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader('Sample_Financial_Statement.pdf')\n",
    "data =  loader.load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0709be-043c-4e15-99e3-f11897bd7954",
   "metadata": {},
   "source": [
    "We need to split the file into smaller chunks for the document to be analyzed. For this we will use the `RecursiveCharacterTextSplitter` class from `langchain.text_splitter` module which will  break down the document into readable chunks for better understanding. The `RecursiveCharacterTextSplitter` is quite versatile and therefore is used in this particular case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc0f706e-bbb7-4809-b310-428f45781658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)\n",
    "docs =  text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c81937-db6f-40ca-b218-33f50391b512",
   "metadata": {},
   "source": [
    "Next we need to import the `GoogleGenerativeAIEmbeddings` to convert the text into vector format which is how the Gemini API will access the records and provide a response. We will also require a database to store the vectors and for that we will import `Chroma` to store the numerical tokens. We will aso require an API key in order to access the Gemini API which will be used for this code. In order to access the key, we will need `load_dotenv` and the API key is stored in the `.env` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4ac5f1e9-c7da-4cea-85fa-efe19defed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embeddings  = GoogleGenerativeAIEmbeddings(model='models/embedding-001')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b19a85d-79ff-41d2-a078-e41a69cc538f",
   "metadata": {},
   "source": [
    "The following step stores the vector into the database that we have created so that they can be accessed afterwards by the bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0e246bf0-7531-43a9-aca2-e4bd06e0dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_vector =  Chroma.from_documents(documents=docs,embedding=GoogleGenerativeAIEmbeddings(model='models/embedding-001'),persist_directory=\"./data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0049067-d21b-4f2a-9878-f0d71e2203c7",
   "metadata": {},
   "source": [
    "After storing the vectorized tokens, we will use the `invoke` command to call the similar values from the document and the number of instances which will be called will be determined by the ` search_kwargs = {\"k\":10}` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e87a5deb-6efe-42e6-b9ae-835fef94ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver = store_vector.as_retriever(search_type =  \"similarity\", search_kwargs = {\"k\":10})\n",
    "retrived_docs = retriver.invoke(\"What is  investment?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf51e00-6166-4e11-a212-311cd05f94b8",
   "metadata": {},
   "source": [
    "We can see that the statement that we have used here is `\"What is  investment?\"` will bring out 10 most similar excerpts from the document and will be stored in the variable. `print(retrived_docs[8].page_content)` command prints out the 8th entry in the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1a3f92cd-c5eb-4be3-876e-ddeba107a9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investments in government bonds                            28                         28                                —                                 — \n",
      "Investments in non convertible debentures                       3,868                    1,793                       2,075                                 — \n",
      "Investment in government securities                       7,632                       7,549                                83                                 — \n",
      "Investments in equity securities                              3                            —                                —                                   3 \n",
      "Investments in preference securities                          193                            —                                —                               193 \n",
      "Investments in commercial papers                          742                            —                              742                             —\n"
     ]
    }
   ],
   "source": [
    "print(retrived_docs[8].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c156be-7511-4ec6-b88d-f33d6a8a3cf0",
   "metadata": {},
   "source": [
    "As can be seen from the text above, the word investment was analysed and then the most similar text was then stored in the variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d8eefa-3cbe-4367-8671-1bae1d691913",
   "metadata": {},
   "source": [
    "We will now import the `ChatGoogleGenerativeAI` from `langchain_google_genai` which will be our large languange model which will help us chat and find answers from the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "16b17ce9-9284-4ba9-91f1-82b9aa3d94ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c178de63-64bc-4ec7-afac-a8e5318bdf30",
   "metadata": {},
   "source": [
    "We are using the `\"gemini-1.5-pro\"` model as our llm and by setting the temperature to 0.3, we  will get less random outputs from the llm and by limiting the max tokens to 500, we will decide to limit the output that we get from the llm to 500 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8b1b629-6392-458c-ae7e-dff5220dd11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm =  ChatGoogleGenerativeAI(model =  \"gemini-1.5-pro\", temperature=0.3,max_tokens=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230524f9-fd09-439e-a497-1c90af99596b",
   "metadata": {},
   "source": [
    "Next we need to create a pipeline wwhich informs the llm on the order of events happening and for that we will assemble a chain by using the ` langchain.chains` module and define the chat prompts using the `ChatPromptTemplate` class from the `langchain.prompts` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bbcc679f-014b-4e03-9c81-37df2ab4923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2fd74e-fd0f-46af-986e-6bb92a95dccf",
   "metadata": {},
   "source": [
    "Now we decide a system prompt which will inform the bot how to respond to queries from the user. The `ChatPromptTemplate` will include the format in which the message is relayed to the llm in order to elicit an answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "be0bc4f1-7b77-4d32-a283-417ac0e8888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an assistant for question answer tasks\"\n",
    "    \"Use the following pieces of retrived context to answer\"\n",
    "    \"the question.If you don't know the answer, say that you\"\n",
    "    \"dont know. Use three sentences maximum  and keep the\"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    "    \n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58123cf-7b14-4065-99eb-01ef49830437",
   "metadata": {},
   "source": [
    "We will create a chain of events which will decide order in which the events will happen for the llm. In this particular case, the llm will get the prompt from the user or human and using the retriver, we will extract an answer from the llm with respect to the query supplied from the human counterpart. The prompt which was defined earlier informs the llm about the format of the response as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4466dda6-8b2f-4eb1-b314-daf92f474f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm,prompt)\n",
    "rag_chain =  create_retrieval_chain(retriver,question_answer_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4609f148-d56a-4a1b-9014-964c63548e26",
   "metadata": {},
   "source": [
    "We will use the bot now to check for responses to the particular file that has been uploaded using the invoke command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a804b548-6564-44af-8198-ce2ad9e85e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infosys Americas Inc. was liquidated on July 14, 2023, and several oddity GmbH subsidiaries merged on September 29, 2023. Infosys Ltd. acquired Danske IT (renamed Idunn Information Technology) on September 1, 2023.  Financial statements show asset balances, additions, deletions, and depreciation through March 31, 2024, along with revenue, expenses, and profit figures. Investment details in various securities are also provided.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"Show me the summary of the file\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "679b65cb-d7a4-4a3a-ad6a-1006875fafb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infosys acquired Danske IT (renamed Idunn Information Technology) on September 1, 2023.  Several oddity GmbH subsidiaries merged into WongDoody GmbH on September 29, 2023. Infosys Americas was liquidated on July 14, 2023.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"Show me the summary of the file\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a44b7ba-df31-49f5-9663-ff88e60db845",
   "metadata": {},
   "source": [
    "As seen from above, we can see that the bot gives answers which are from the document and due to the temperature=0.3 parameter, we can get slight randomness in each response, which is characterized by its uniqueness in the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a6585d3-342c-4b48-94f9-5b76bc1fdc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gross profit for Q3 2024 is ₹11,175 crore.  This is calculated as revenue from operations less cost of sales.  The information is found in the provided condensed consolidated statement of profit and loss.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is the gross profit for Q3 2024?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0565d069-497e-450f-bc51-7c0017cf189b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided information is a consolidated statement of profit and loss, it does not contain comprehensive income data.  It does show operating expenses totaling ₹3,554 crore in Q1 2024. Therefore, I cannot provide a comparison without the comprehensive income figure.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"How do the comprehensive income and operating expenses compare for Q1 2024?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cd15872c-18ec-43ba-9558-7482557fddba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cash flows from financing activities:\n",
      "\n",
      "| Item                                            | Current Year | Prior Year |\n",
      "|-------------------------------------------------|-------------:|-----------:|\n",
      "| Payment of lease liabilities                    |     (2,024) |    (1,231) |\n",
      "| Payment of dividends                            |    (14,692) |   (13,631) |\n",
      "| Payment of dividend to non-controlling interest |        (39) |       (22) |\n",
      "| Buyback of shares (non-controlling interest)    |        (18) |         — |\n",
      "| Shares issued (employee stock options)          |          5 |        35 |\n",
      "| Other receipts                                  |          - |       132 |\n",
      "| Other payments                                   |       (736) |      (479) |\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"Show me the table for Cash flows from financing activities\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "258c61ce-4f99-44cb-a0aa-75a1b83762eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net assets were ₹103 crore. Intangible assets included customer contracts and relationships (₹274 crore), vendor relationships (₹30 crore), and brand (₹24 crore), with deferred tax liabilities on intangible assets of ₹(80) crore.  The total purchase price allocated was ₹351 crore.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What are the acquisitions during the year ended March 31, 2023\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "75e67a24-f31b-44db-a4ce-5b8195aa01b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infosys proposed two acquisitions in 2024.  They planned to acquire in-tech Holding GmbH, a German Engineering R&D services provider, for up to €450 million.  They also proposed acquiring InSemi Technology Services Private Limited, an Indian semiconductor design services company, for up to ₹280 crore.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What are the proposed acquisitions during the year 2024?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "20deba97-f125-4338-be7b-5307ff2e9320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The company assesses contracts at inception to determine if they contain a lease based on control of an identified asset.  Lease liabilities are initially measured at amortized cost, using the present value of future lease payments.  Claims against the group are categorized as contingent liabilities, particularly those related to tax matters.  The company also recognizes various expenses such as rates and taxes, consumables, insurance, and contributions to corporate social responsibility.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is the accounting policy of the company? Answer in 4 sentences\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f2651a-60f5-4d32-bb8c-20a797b6d472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
